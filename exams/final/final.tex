\documentclass[12pt]{article}

\include{preamble}

\title{Math 341 / 650 Spring 2017 \\ Final Examination}
\author{Professor Adam Kapelner}

\date{Thursday, May 25, 2017}

\begin{document}
\maketitle

\noindent Full Name \line(1,0){410}

\thispagestyle{empty}

\section*{Code of Academic Integrity}

\footnotesize
Since the college is an academic community, its fundamental purpose is the pursuit of knowledge. Essential to the success of this educational mission is a commitment to the principles of academic integrity. Every member of the college community is responsible for upholding the highest standards of honesty at all times. Students, as members of the community, are also responsible for adhering to the principles and spirit of the following Code of Academic Integrity.

Activities that have the effect or intention of interfering with education, pursuit of knowledge, or fair evaluation of a student's performance are prohibited. Examples of such activities include but are not limited to the following definitions:

\paragraph{Cheating} Using or attempting to use unauthorized assistance, material, or study aids in examinations or other academic work or preventing, or attempting to prevent, another from using authorized assistance, material, or study aids. Example: using an \emph{unauthorized} cheat sheet in a quiz or exam, altering a graded exam and resubmitting it for a better grade, etc.
\\

\noindent I acknowledge and agree to uphold this Code of Academic Integrity. \\

\begin{center}
\line(1,0){250} ~~~ \line(1,0){100}\\
~~~~~~~~~~~~~~~~~~~~~signature~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ date
\end{center}

\normalsize

\section*{Instructions}

This exam is seventy five minutes and closed-book. You are allowed \textbf{three} pages (front and back) of \qu{cheat sheets.} You may use a graphing calculator of your choice. Please read the questions carefully. If the question reads \qu{compute,} this means the solution will be a number otherwise you can leave the answer in \textit{any} widely accepted mathematical notation which could be resolved to an exact or approximate number with the use of a computer. I advise you to skip problems marked \qu{[Extra Credit]} until you have finished the other questions on the exam, then loop back and plug in all the holes. I also advise you to use pencil. The exam is 100 points total plus extra credit. Partial credit will be granted for incomplete answers on most of the questions. \fbox{Box} in your final answers. Good luck!

\pagebreak


\begin{table}[htp]
\centering
\small
\begin{tabular}{l | llll}
Distribution                  & Quantile  & PMF / PDF  &CDF       & Sampling  \\ 
of r.v. &  Function & function         & function &  Function \\ \hline
beta & \texttt{qbeta}($p$, $\alpha$, $\beta$)             
& \texttt{d-}($x$, $\alpha$, $\beta$)
& \texttt{p-}($x$, $\alpha$, $\beta$) 
& \texttt{r-}($\alpha$, $\beta$) \\
betabinomial & \texttt{qbetabinom}($p$, $n$, $\alpha$, $\beta$)              
& \texttt{d-}($x$, $n$, $\alpha$, $\beta$)
& \texttt{p-}($x$, $n$, $\alpha$, $\beta$) 
& \texttt{r-}($n$, $\alpha$, $\beta$) \\

betanegativebinomial & \texttt{qbeta\_nbinom}($p$, $r$, $\alpha$, $\beta$) 
& \texttt{d-}($x$, $r$, $\alpha$, $\beta$)
& \texttt{p-}($x$, $r$, $\alpha$, $\beta$) 
& \texttt{r-}($r$, $\alpha$, $\beta$) \\

binomial & \texttt{qbinom}($p$, $n$, $\theta$) 
& \texttt{d-}($x$, $n$, $\theta$)
& \texttt{p-}($x$, $n$, $\theta$) 
& \texttt{r-}($n$, $\theta$) \\

exponential & \texttt{qexp}($p$, $\theta$) 
& \texttt{d-}($x$, $\theta$) 
& \texttt{p-}($x$, $\theta$) 
& \texttt{r-}($\theta$) \\

gamma & \texttt{qgamma}($p$, $\alpha$, $\beta$) 
& \texttt{d-}($x$, $\alpha$, $\beta$)
& \texttt{p-}($x$, $\alpha$, $\beta$) 
& \texttt{r-}($\alpha$, $\beta$) \\

geometric & \texttt{qgeom}($p$, $\theta$) 
& \texttt{d-}($x$, $\theta$)
& \texttt{p-}($x$, $\theta$) 
& \texttt{r-}($\theta$) \\

inversegamma & \texttt{qinvgamma}($p$, $\alpha$, $\beta$) 
& \texttt{d-}($x$, $\alpha$, $\beta$)
& \texttt{p-}($x$, $\alpha$, $\beta$) 
& \texttt{r-}($\alpha$, $\beta$) \\

negative-binomial & \texttt{qnbinom}($p$, $r$, $\theta$) 
& \texttt{d-}($x$, $r$, $\theta$) 
& \texttt{p-}($x$, $r$, $\theta$) 
& \texttt{r-}($r$, $\theta$) \\

normal (univariate) & \texttt{qnorm}($p$, $\theta$, $\sigma$) 
& \texttt{d-}($x$, $\theta$, $\sigma$)
& \texttt{p-}($x$, $\theta$, $\sigma$) 
& \texttt{r-}($\theta$, $\sigma$) \\

normal (multivariate) & 
& \multicolumn{2}{l}{\texttt{dmvnorm}($\x$, $\muvec$, $\bSigma$)} 
& \texttt{r-}($\muvec$, $\bSigma$) \\

poisson & \texttt{qpois}($p$, $\theta$) 
& \texttt{d-}($x$, $\theta$)
& \texttt{p-}($x$, $\theta$) 
& \texttt{r-}($\theta$) \\

T (standard) & \texttt{qt}($p$, $\nu$) 
& \texttt{d-}($x$, $\nu$) 
& \texttt{p-}($x$, $\nu$)
& \texttt{r-}($\nu$) \\

T (nonstandard) & \texttt{qt.scaled}($p$, $\nu$, $\mu$, $\sigma$) 
& \texttt{d-}($x$, $\nu$, $\mu$, $\sigma$)
& \texttt{p-}($x$, $\nu$, $\mu$, $\sigma$) 
& \texttt{r-}($\nu$, $\mu$, $\sigma$) \\

uniform & \texttt{qunif}($p$, $a$, $b$) 
& \texttt{d-}($x$, $a$, $b$)
& \texttt{p-}($x$, $a$, $b$) 
& \texttt{r-}($a$, $b$) \\
\end{tabular}
\caption{Functions from $\texttt{R}$ (in alphabetical order) that can be used on this exam. The hyphen in colums 3, 4 and 5 is shorthand notation for the full text of the r.v. which can be found in column 2.
}
\label{tab:eqs}
\end{table}

\problem Assume a binomial likelihood with a known sample size $n$ with a beta prior with parameters $\alpha$ and $\beta$.

\benum

\subquestionwithpoints{3} What is the kernel of $\prob{\theta}$? \spc{3}

\subquestionwithpoints{3} What is the kernel of $\cprob{\theta}{X,~n}$? \spc{3}

\subquestionwithpoints{4} What is the kernel of $\cprob{\theta,~X}{n}$? \spc{3}


\subquestionwithpoints{5} Find $\int \cprob{\theta,~X}{n} d\theta$ explicitly (i.e. saying the answer is e.g. $\cprob{\theta}{X}$ is unacceptable. You can use any notation we used in class. Hint: nothing from Table~\ref{tab:eqs} is the answer. \spc{5}

\subquestionwithpoints{6} Create a Gibbs sampler that will sample from $\cprob{\theta,~X}{n}$. Outline the steps of the sampler and describe explicitly how you do each step using functions from Table~\ref{tab:eqs}. You do not need to write about burning and thinning. \spc{11}



\subquestionwithpoints{2} [Extra Credit] If the $X$'s resulting from the Gibbs sampler were examined after burning and thinning, what would $\oneover{n} \sum x_i$ be approximately equal to? \spc{1}
\eenum


\problem The table below displays an excerpt of daily historical data of the S\&P500 index for American equities going back to 1950, a total of $n = 16,428$ days. You had a similar dataset for the homework, but that was yearly returns.

\begin{table}[htp]
\centering
\begin{tabular}{c|cc}
Day  & Ending Price & Gain or Loss (\%) \\ \hline
1/4/1950 &16.85  & 1.14 \\
1/5/1950   & 16.93  & 0.47 \\
1/6/1950    &16.98  & 0.29 \\
1/9/1950    & 17.08  &0.58 \\
1/10/1950   & 17.03 & -0.29 \\
\vdots  
\end{tabular}
\end{table}

\noindent For the daily percent gains (or losses) we calculate the sample average and sample standard deviation: 

\beqn
\xbar &=& 0.03\% \\
s &=& 0.97\%
\eeqn

\noindent We also assume that the daily percent gains (or losses) is modeled via

\beqn
\Xoneton ~|~\theta,\sigsq \iid \normnot{\theta}{\sigsq}
\eeqn

For the remainder of this problem, you are to answer explicitly using numbers for all arguments.  If you use any substitutions, make it clear as to the value of or how the substitutions are calculated. They can only be a function of the $x_i$'s.

\benum

\subquestionwithpoints{4} Assume $\sigsq$ was known to be $0.97\%^2$, what is the distribution of $\theta$ given the data? Assume $\theta \sim \normnot{0\%}{100\%^2}$. Compute explicitly for this problem and the remainder of this question. \spc{9}

\subquestionwithpoints{4} Assume $\theta$ was known to be 0.03\%, what is the distribution of $\sigsq$ given the data?  Assume $\prob{\sigsq} \propto 1 / \sigsq$. \spc{5}

\subquestionwithpoints{4} Assume neither $\theta$ nor $\sigsq$ was known, what is the distribution of $\theta$ given the data assuming the Jeffrey's prior for the parameters? \spc{5}

\subquestionwithpoints{4} Assume neither $\theta$ nor $\sigsq$ was known, what is the distribution of $\sigsq$ given the data assuming the Jeffrey's prior for the parameters? \spc{5}

\subquestionwithpoints{4} Assume neither $\theta$ nor $\sigsq$ was known, what is the distribution of tomorrow's return given the data assuming the Jeffrey's prior for the parameters? \spc{5}

\subquestionwithpoints{6} [Extra Credit] Assume neither $\theta$ nor $\sigsq$ was known and assume the priors in (a) and (b). Explain how you would sample pairs  $\bracks{\theta, \sigsq}$ from $\cprob{\theta,~\sigsq}{X}$. Use functions from Table~\ref{tab:eqs}. \spc{10}

\subquestionwithpoints{4} Using your answer from (d), provide a 99\% credible region for $\sigsq$. Use functions from Table~\ref{tab:eqs}. \spc{3}

\subquestionwithpoints{4} Using your answer from (e), provide a 95\% credible region for tomorrow's return. Use functions from Table~\ref{tab:eqs}. \spc{4}

\subquestionwithpoints{4} We now want to make sure we picked a realistic likelihood model and realistic priors on its parameters (the uninformative Jeffrey's prior). We plot the true data and seven replicates using $\cprob{X^*}{X}$ where the dimension of $X^*$ is the same as of $X$, i.e. $n=16428$. You can see the result in Figure~\ref{fig:model_check} on page~\pageref{fig:model_check}. Was our choice for the likelihood (and priors) a good choice to model this data? Yes / no. If not, where exactly did we go wrong? \spc{2}



\eenum

\begin{figure}[h]
\centering
\includegraphics[width=7in]{data_and_reps}
\caption{Replicates of the original data assuming the model and the prior.}
\label{fig:model_check}
\end{figure}


\problem A call center at a large company receives many calls per day. In each minute, calls are approximately Poisson distributed as they are the result of millions of potential callers with a minuscule probability each can call in. For a particular day, the manager is trying to locate the \qu{slightly busier period} between the calm period of the early morning and the calm period of the late evening. Figure~2 on page \pageref{fig:call_data} shows a plot of a day's data where each point is the number of calls in one minute for all 24 hours:

\begin{figure}[h]
\centering
\includegraphics[width=6in]{call_data}
\label{fig:call_data}
\caption{The call data.}
\end{figure}

You can barely see there is a busy period sandwiched between two calm periods. We will now build a Bayesian model to detect all parameters:

\begin{itemize}
\item $m_1$ --- the first change point i.e. the minute of the day that indicates the transition from the calm of the morning to the busy of the day
\item $m_2$ --- the second change point i.e. the minute of the day that indicates the transition from the busy of the day to the calm of the evening
\item $\lambda_c$ --- the mean number of calls during the calm of the morning \textit{and} evening
\item $\lambda_b$ --- the mean number of calls during the busy part of the day
\end{itemize}

We will assume each caller is independent. Let $x_1, x_2, \ldots, x_{n}$ represent the data (where $n=1440$, the number of minutes in a 24hr day). For example, $x_{20}$ is the number of calls in the 20th minute of the day i.e. from 12:19:00AM to 12:19:59AM.



\benum

\subquestionwithpoints{6} Write the likelihood of the model. Answer as explicitly as possible. \spc{6}

\subquestionwithpoints{3} Assume the prior of Gamma(0, 0) for both $\lambda_c$ and $\lambda_b$ and assume a discrete uniform prior for $m_1$ and $m_2$. Write each prior formally and indicate if each of them are proper or improper. \spc{3}


\subquestionwithpoints{6} Assume the likelihood model from (a) and the priors from (b). Find the kernel of the posterior. \spc{6}


\subquestionwithpoints{6} Assume your expression for proportional posterior from (c). Find $\cprob{\lambda_b}{x_1, \ldots, x_n, \lambda_c, m_1, m_2}$. \spc{3}

\subquestionwithpoints{4} Using the conditional from (d) and all other conditionals, we build a Gibbs sampler with 1,000 iterations. Figure~3 on page \pageref{fig:burn} shows the first 80 iterations of each chain. It seems to burn in right away, at about the 10th iteration. Figure~4 on page \pageref{fig:acf} shows the autocorrelation of the chains. After thinning the burned-in chains, how many samples are we left with from the posterior? \spc{2}

\subquestionwithpoints{2} Are these \qu{left over samples} considered $\iid$? Yes / no.

\subquestionwithpoints{4} Figure~5 on page \pageref{fig:marginals} shows the histograms from the burned and thinned chains. Provide an approximate 95\% credible region for $m_2$.  \spc{3}

\subquestionwithpoints{3} Approximate the MMSE Bayesian estimate for $\lambda_c$.  \spc{1}

\subquestionwithpoints{3} Approximate the MAE Bayesian estimate for $\lambda_b$.  \spc{1}

\subquestionwithpoints{4} Test if $m_1$ is greater than 500.  \spc{3}

\subquestionwithpoints{6} Devise a means to test $H_0$: there was no busy period to begin with i.e. for the whole day there was only one homogeneous Poisson.

\eenum

\begin{figure}[htp]
\centering
\includegraphics[width=6.5in]{burn}
\label{fig:burn}
\caption{First 80 iterations of the Gibbs sampler in Problem 3.}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=6.5in]{acf}
\label{fig:acf}
\caption{Autocorrelation estimates for the Gibbs sampler after burn-in in Problem 3.}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=6.5in]{marginals}
\label{fig:marginals}
\caption{Histograms for the Gibbs sampler after burn-in and thinning in Problem 3.}
\end{figure}


\end{document}

